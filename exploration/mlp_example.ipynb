{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3670/3670 [10:11<00:00,  6.01it/s]\n"
     ]
    }
   ],
   "source": [
    "mfcc_dict = {}\n",
    "sound_path = os.path.join(\"..\", \"data\", \"sounds\")\n",
    "max_sound_length = 173\n",
    "\n",
    "for file in tqdm(glob.glob(os.path.join(sound_path, \"*.wav\"))):\n",
    "    sound_id = file[len(sound_path + \"/\"):-len(\".wav\")]\n",
    "    mfcc = librosa.feature.mfcc(*librosa.load(file))\n",
    "    mfcc = librosa.util.fix_length(mfcc, max_sound_length)\n",
    "    mfcc_dict[int(sound_id)] = mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.42579995e+02,  -2.49812213e+02,  -2.67513318e+02, ...,\n",
       "         -2.67675760e+02,  -2.57069240e+02,  -2.28439155e+02],\n",
       "       [  1.32293902e+02,   1.54785994e+02,   1.76246104e+02, ...,\n",
       "          1.78335009e+02,   1.65681229e+02,   1.29929888e+02],\n",
       "       [  7.60230122e+01,   6.65809508e+01,   4.24261387e+01, ...,\n",
       "          4.10531854e+01,   5.22641242e+01,   5.11131522e+01],\n",
       "       ..., \n",
       "       [ -2.85158617e+00,  -5.29948492e+00,  -1.02560000e+01, ...,\n",
       "         -3.13509516e+00,  -7.69428484e+00,  -9.87785389e+00],\n",
       "       [ -1.64310428e+00,  -4.57154473e+00,  -9.01730536e+00, ...,\n",
       "         -1.35508123e+00,  -6.15971884e+00,  -8.64188705e+00],\n",
       "       [ -3.89875712e+00,  -5.58660890e+00,  -1.38850054e-01, ...,\n",
       "         -1.26545881e+00,  -3.58002005e+00,  -4.30527391e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_dict[666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/mfcc/mfcc_dict.z']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_filepath = os.path.join(\"..\", \"data\", \"mfcc\", \"mfcc_dict.z\")\n",
    "joblib.dump(mfcc_dict, mfcc_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_dict = joblib.load(mfcc_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID         Class\n",
       "0   0         siren\n",
       "1   1  street_music\n",
       "2   2      drilling\n",
       "3   3         siren\n",
       "4   4      dog_bark"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dir = os.path.join(\"..\", \"data\", \"labels\")\n",
    "df_labels = pd.read_csv(os.path.join(label_dir, \"train_short.csv\"))\n",
    "df_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 20, 173)\n",
      "(136, 3460)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<136x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 136 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "train_mfcc_2D = [mfcc_dict[mfcc_id] for mfcc_id in df_labels.loc[:, \"ID\"]]\n",
    "train_mfcc_2D = np.stack(train_mfcc_2D)\n",
    "train_mfcc_1D = train_mfcc_2D.reshape(136, -1)\n",
    "print(train_mfcc_2D.shape)\n",
    "print(train_mfcc_1D.shape)\n",
    "labels = df_labels.loc[:, \"Class\"]\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "int_labels = label_enc.fit_transform(labels)\n",
    "\n",
    "one_hot_enc = OneHotEncoder()\n",
    "y = one_hot_enc.fit_transform(int_labels.reshape(-1, 1))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "mlp = keras.models.Sequential()\n",
    "mlp.add(Dense(64, input_shape=(train_mfcc_1D.shape[1],), activation=\"relu\"))\n",
    "mlp.add(BatchNormalization())\n",
    "mlp.add(Dense(64, activation=\"relu\"))\n",
    "mlp.add(BatchNormalization())\n",
    "mlp.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<33x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 33 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data TODO: use a function <.<\n",
    "\n",
    "df_labels = pd.read_csv(os.path.join(label_dir, \"test.csv\"))\n",
    "test_mfcc_2D = [mfcc_dict[mfcc_id] for mfcc_id in df_labels.loc[:, \"ID\"]]\n",
    "test_mfcc_2D = np.stack(test_mfcc_2D)\n",
    "test_mfcc_1D = test_mfcc_2D.reshape(test_mfcc_2D.shape[0], -1)\n",
    "test_labels = df_labels.loc[:, \"Class\"]\n",
    "\n",
    "test_label_enc = LabelEncoder()\n",
    "test_int_labels = test_label_enc.fit_transform(test_labels)\n",
    "\n",
    "test_one_hot_enc = OneHotEncoder()\n",
    "test_y = test_one_hot_enc.fit_transform(test_int_labels.reshape(-1, 1))\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "epoch 1: test_acc=0.515, train_acc=0.85\n",
      "epoch 2: test_acc=0.273, train_acc=0.86\n",
      "epoch 3: test_acc=0.545, train_acc=0.98\n",
      "epoch 4: test_acc=0.424, train_acc=0.94\n",
      "epoch 5: test_acc=0.485, train_acc=1.0\n",
      "epoch 6: test_acc=0.333, train_acc=0.95\n",
      "epoch 7: test_acc=0.333, train_acc=0.96\n",
      "epoch 8: test_acc=0.394, train_acc=0.94\n",
      "epoch 9: test_acc=0.424, train_acc=0.81\n",
      "epoch 10: test_acc=0.424, train_acc=0.96\n"
     ]
    }
   ],
   "source": [
    "mlp.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "print(mlp.metrics_names)\n",
    "for epoch in range(10):\n",
    "    mlp.fit(train_mfcc_1D, y, epochs=10, batch_size=32, verbose=0)\n",
    "    test_acc = mlp.evaluate(test_mfcc_1D, test_y, verbose=0)[1]\n",
    "    train_acc = mlp.evaluate(train_mfcc_1D, y, verbose=0)[1]\n",
    "    print(f\"epoch {epoch + 1}: test_acc={test_acc:.3}, \"\n",
    "          f\"train_acc={train_acc:.2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
